{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNR07GF9D8GELEIhUFxPQ20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athugodage/Gazprom_test/blob/main/gazprom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3a_HuGdd08Y"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/кейс - Разработчик NLP.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/nlp/journals_shot.zip'"
      ],
      "metadata": {
        "id": "HnUds7DOeq6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/journals_shot.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "AXXxvx25eNwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Ycfs0q1nfEFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code2text = pd.read_csv('/content/nlp/codeToText.tsv', sep='\\t', header=None)\n",
        "code2text"
      ],
      "metadata": {
        "id": "XHCQOc_mfHQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработка данных"
      ],
      "metadata": {
        "id": "-xpl9xOJpd9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = dict()\n",
        "\n",
        "for ind in code2text.index:\n",
        "    code = code2text[0].iloc[ind]\n",
        "    text = code2text[1].iloc[ind]\n",
        "    d[code] = text\n",
        "\n",
        "print(d)"
      ],
      "metadata": {
        "id": "vSRF_ZNjn-BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## создаем столбец с русскоязычными действиями\n",
        "\n",
        "df['eventText'] = df['eventCode'].apply(lambda x: d[x])"
      ],
      "metadata": {
        "id": "7GyIRXscpJ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['eventTime'] = pd.to_datetime(df['eventTime'])\n",
        "df['time'] = df['eventTime'].apply(lambda x: x.time().hour)"
      ],
      "metadata": {
        "id": "vJ0pnzHNpmUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1.**\n",
        "\n",
        "1) Сколько всего пользователей?"
      ],
      "metadata": {
        "id": "eeDMRG3qhxXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Всего пользователей: ', len(set(df['userId'])))"
      ],
      "metadata": {
        "id": "0uHyTNvniWwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) В какое время суток пользователи заходят?"
      ],
      "metadata": {
        "id": "YWGSk7LkiqPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['eventText'] == 'Просмотрен объект']"
      ],
      "metadata": {
        "id": "9PznzNZ0vwGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  смотрим частотату захода по каждому часу\n",
        "\n",
        "freq = df[df['eventText'] == 'Просмотрен объект'].groupby('time', as_index=False).agg({'id':'count'})"
      ],
      "metadata": {
        "id": "e0m-CoZein_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq"
      ],
      "metadata": {
        "id": "LwxKO0mSw772"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = freq['time']  \n",
        "y = freq['id']  # times of entry\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y)\n",
        "\n",
        "plt.xlabel('Часы')\n",
        "plt.ylabel('Количество просмотров')\n",
        "plt.title('Частота просматриваемости за сутки')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "##  как видно из графика, больше всего заходят (если быть точным, просматривают объект)\n",
        "##  с 9:00 по 16:00"
      ],
      "metadata": {
        "id": "hOWfHmLoxDo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сколько действий совершают пользователи?"
      ],
      "metadata": {
        "id": "sSOI7oCOyHZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = df.groupby('eventText', as_index=False).agg({'userId': 'count'})\n"
      ],
      "metadata": {
        "id": "urjl_rcCzBB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events"
      ],
      "metadata": {
        "id": "kFR3zIo_5wF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events.loc[len(events.index)] = ['Другое', events[events['userId'] < 500]['userId'].agg('sum')]"
      ],
      "metadata": {
        "id": "6aDuTjRQ2wYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_list = events[events['userId'] > 500]['eventText'].to_list()\n",
        "event_freq = events[events['userId'] > 500]['userId'].to_list()\n",
        "event_list"
      ],
      "metadata": {
        "id": "5NWW5Lm22U0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Creating autocpt arguments\n",
        "def func(pct, allvalues):\n",
        "    absolute = int(pct / 100.*np.sum(allvalues))\n",
        "    return absolute/1000\n",
        "\n",
        "colors = ( \"orange\", \"cyan\", \"brown\",\n",
        "          \"grey\", \"indigo\", \"beige\", \"pink\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(20, 15))\n",
        "wedges, texts, autotexts = ax.pie(event_freq,\n",
        "                                  autopct = lambda pct: func(pct, event_freq),\n",
        "                                  shadow = True,\n",
        "                                  colors = colors,\n",
        "                                  startangle = 90,\n",
        "                                  textprops = dict(color =\"black\"))\n",
        "\n",
        "ax.legend(wedges, event_list,\n",
        "          title =\"Действия\",\n",
        "          loc =\"center left\",\n",
        "          bbox_to_anchor =(1, 0, 0.5, 1))\n",
        "\n",
        "ax.set_title(\"Кол-во (в тысячах) каждого действия из всех совершенных\")\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C_3e8IFjhUC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2.\n",
        "\n",
        "1) Что ищут пользователи? Провести группировку запросов, выделить похожие и однотипные"
      ],
      "metadata": {
        "id": "RsTF7Kxk9QJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "df['searchQuery'] = df[df['eventText'] == 'Выполнен поиск']['content'].apply(lambda x: json.loads(x)[\"docRequest\"]['query'])\n",
        "\n",
        "## этот столбец позволяет увидеть поисковый запрос пользователя"
      ],
      "metadata": {
        "id": "pcFyKtrq8nqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = df[df['eventText'] == 'Выполнен поиск'].groupby('searchQuery', \n",
        "                                                as_index=False).agg({\n",
        "                                                    'id': 'count'\n",
        "                                                    }).sort_values(by=['id'], \n",
        "                                                    ascending=False)\n",
        "\n",
        "queries.head(20)\n",
        "##  Вывели 20 самых популярных запросов\n",
        "##  Самый популярный запрос - пустой (14992)"
      ],
      "metadata": {
        "id": "NmmJe4THGXfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "## Вариант 1 (rule-based). Можно сгруппировать запросы по тому есть ли там ключевые слова \"газпром\", \"нефть\", \"шельф\", \"разработка\", \"грейд\" или нет\n",
        "\n",
        "def check(query):\n",
        "    if str(query) in ('газпром', 'нефть', 'шельф', 'разработка', 'грейд'):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "    \n",
        "queries['oil-related'] = queries['searchQuery'].apply(check)\n",
        " \n"
      ],
      "metadata": {
        "id": "1BXOPo00S2ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "id": "dnkA-s08d-YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "##  Вариант 2. Кластеризация с KMeans\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(queries['searchQuery'])"
      ],
      "metadata": {
        "id": "CbyTonKOKkg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "predicted = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "mfl3Txba6MDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "distribution = pd.DataFrame({'Queries': queries['searchQuery'], \n",
        "                             'Cluster': predicted}).groupby('Cluster', \n",
        "                                                            as_index=False).agg('count')\n",
        "distribution\n"
      ],
      "metadata": {
        "id": "FHcWHPXb6Tj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  Делаем график чтобы увидеть распределение запросов по кластерам\n",
        "#  Оказывается, что в распредление не нормально, 1 кластер огромный, а остальные меньше\n",
        "\n",
        "plt.scatter(distribution['Cluster'], \n",
        "               distribution['Queries'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4id9CrtDskxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=7)\n",
        "predicted = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "sLUaf_gFhfx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_kmeans = pd.DataFrame({'Queries': queries['searchQuery'], \n",
        "              'Cluster': predicted})"
      ],
      "metadata": {
        "id": "DoOeoU38jPW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution = result_kmeans.groupby('Cluster', as_index=False).agg('count')\n",
        "distribution\n",
        "## как видим, результат примерно тот же самый, но кластеры \"более равномерные\""
      ],
      "metadata": {
        "id": "ugnwVbDwoAvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_kmeans\n",
        "\n",
        "##  смотрим таблицу, где указан кластер каждого текста"
      ],
      "metadata": {
        "id": "lJe4c9Oo7S98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_kmeans[result_kmeans['Cluster'] == 3]\n",
        "\n",
        "##  смотрим все запросы из 3 кластера"
      ],
      "metadata": {
        "id": "GfrHQ81r7em7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "##  Вариант 3. Кластеризация с DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=1.13, min_samples=100)\n",
        "predicted = dbscan.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "ZSSa3vFm8A_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dbscan = pd.DataFrame({'Queries': queries['searchQuery'], \n",
        "              'Cluster': predicted})\n",
        "\n",
        "result_dbscan"
      ],
      "metadata": {
        "id": "QHHLP_j2_2EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution = result_dbscan.groupby('Cluster', as_index=False).agg('count')\n",
        "distribution\n",
        "\n",
        "##  получается 2 больших кластера и помельче. \n",
        "##  сравнил с другими вариантами eps. \n",
        "##  Если ставить 0.5, то будет один большой кластер и куча мелких\n",
        "##  Если ставить 2, т будет один большой кластер и 2 маленьких\n",
        "##  C eps=1.13 тоже много мелких кластеров, но зато есть два крупных\n",
        "##  Чтобы не было мелких кластеров, использовал параметр min_samples=100"
      ],
      "metadata": {
        "id": "qrax1lL8_6Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для сгруппированных запросов выделить группы запросов для которых свойственно\n",
        "переход в источник (после выполнения поиска с большой вероятностью случается событие\n",
        "ObjectViewedJournalEvent);"
      ],
      "metadata": {
        "id": "_6s3l97pBm11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##  будем использовать результат кластеризации KMeans\n",
        "\n",
        "data = pd.DataFrame({'Queries': result_kmeans['Queries'],\n",
        "                     'eventCode': df['eventCode'],\n",
        "                     'cluster': result_kmeans['Cluster']}, \n",
        "                    index=result_kmeans.index)"
      ],
      "metadata": {
        "id": "-Ifv3s6uJIsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data[data['eventCode'] == 'ObjectViewedJournalEvent'].groupby('cluster', as_index=False).agg({'Queries': 'count'})\n",
        "\n",
        "\n",
        "##  Как видно, кластер которому больше всего свойственно переход в источник - нулевой."
      ],
      "metadata": {
        "id": "CeYO5F8aLu39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dist = data[data['eventCode'] == 'ObjectViewedJournalEvent'].groupby('cluster', as_index=False).agg({'Queries': 'count'})\n",
        "\n",
        "plt.bar(dist['cluster'], dist['Queries'])\n",
        "\n",
        "plt.xlabel('Кластеры запросов')\n",
        "plt.ylabel('Кол-во переходов в источник')\n",
        "plt.title('Переходы в источник для каждого из кластера')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MOzxsCt2PjcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Анализ текста запроса. Выделить из текста запроса: имена, аббревиатуры, опечатки,\n",
        "шифры и тд"
      ],
      "metadata": {
        "id": "IhqipDtfRDs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "id": "oirWoZ2xTreY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "5aAFG1f2RAdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(30)"
      ],
      "metadata": {
        "id": "JkFIMUWqUAcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ],
      "metadata": {
        "id": "lujFpgtsVflJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def ner(query):\n",
        "    doc = nlp(str(query))\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == 'PER':  ## ищем только такие сущности, т.к. они дают имена \n",
        "            return ent.text\n",
        "\n",
        "\n",
        "data['Named Entities'] = data['Queries'].progress_apply(ner)  ## ищем имена\n",
        "data"
      ],
      "metadata": {
        "id": "osIU1lD3TzJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['Named Entities'].str.contains('None')==False]  \n",
        "\n",
        "## выводит все запросы в которых есть имена.\n",
        "## у модели случаются ошибки. Например, \"Мессояханефтегаз\" определили как человека"
      ],
      "metadata": {
        "id": "YuMPVleqY972"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def find_abbrevs(query):\n",
        "    abbrevs = []\n",
        "    tokens = str(query).split(' ')\n",
        "    for token in tokens:\n",
        "        abbrev = re.search('[А-Я]{2,}', token)\n",
        "        if abbrev is not None:\n",
        "            abbrevs.append(abbrev.group(0))\n",
        "\n",
        "\n",
        "    if len(abbrevs) >= 1:\n",
        "        return abbrevs\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "data['Abbreviations'] = data['Queries'].progress_apply(find_abbrevs)  ## ищем аббревиатуры"
      ],
      "metadata": {
        "id": "jB7Eu7ZeZTPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "WbcZvNr1a1QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def find_chiffre(query):\n",
        "    abbrevs = []\n",
        "    tokens = str(query).split(' ')\n",
        "    for token in tokens:\n",
        "        abbrev = re.search('\\w+-[\\d{2,}.]{2,}', token)\n",
        "        if abbrev is not None:\n",
        "            abbrevs.append(abbrev.group(0))\n",
        "\n",
        "\n",
        "    if len(abbrevs) >= 1:\n",
        "        return abbrevs\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "data['Chiffre'] = data['Queries'].progress_apply(find_chiffre)  ## Ищем шифры"
      ],
      "metadata": {
        "id": "s6XR155BZ1Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "CN2tlWU4fBih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}